{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network (RNN) - Deep Learning\n",
    "Son redes de aprendizaje profundo cuyo propósito se enmarca en la predicción basada en series de tiempo, son particularmente usadas en procesamiento de video y en tareas de NLP para sugerir palabras (text completion). No obstante pueden usarse para generación de expresiones matemáticas con un enfoque relativamente nuevo propuesto aquí: https://openreview.net/pdf?id=m5Qsh0kBQG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T06:25:43.163056Z",
     "start_time": "2022-05-31T06:25:25.801466Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.utils.random import check_random_state\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo RNN\n",
    "Se aplicará una RNN para predecir la distancia entre un par de puntos (x,y) y (x1,y1), uno de ellos constante.$$ d = \\sqrt{(x1-x)^2 + (y1 - y)^2} $$ <br>\n",
    "Como son redes que aplican para problemas basados en series de tiempo, se decidió que cada 100 registros se haría un timestep para especificar el número de observaciones previas cuando la RNN haga una predicción sobre la observación actual.<br>\n",
    "### Generar el conjunto de datos\n",
    "Para generar el conjunto de datos se calculará la distancia entre un conjunto de 5000 puntos (x,y) aleatorios, así, el modelo de regresión se ajustará a una proporción del 80% del conjunto y el 20% restante estará destinado a la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T09:56:24.268344Z",
     "start_time": "2022-05-31T09:56:20.438424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4900, 100)\n",
      "(4900,)\n",
      "(4900, 100, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid keyword argument(s) in `compile`: {'verbose'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c44ab5fdb1ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_training_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_training_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m       \u001b[0mfrom_serialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'from_serialized'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_validate_compile\u001b[1;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[0;32m   2619\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minvalid_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2620\u001b[0m       raise TypeError('Invalid keyword argument(s) in `compile`: %s' %\n\u001b[1;32m-> 2621\u001b[1;33m                       (invalid_kwargs,))\n\u001b[0m\u001b[0;32m   2622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2623\u001b[0m     \u001b[1;31m# Model must be created and compiled with the same DistStrat.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid keyword argument(s) in `compile`: {'verbose'}"
     ]
    }
   ],
   "source": [
    "def calcular_distancia(X,Y,XF,YF):\n",
    "    return np.round(np.sqrt(np.power(XF-X,2)+np.power(YF-Y,2)),2)\n",
    "\n",
    "XF = 5\n",
    "YF = 12.5\n",
    "\n",
    "rng = check_random_state(0)\n",
    "\n",
    "X = np.round(rng.uniform(1, 11, 10000).reshape(5000, 2),2)\n",
    "XFs=[[XF] for i in range(5000)]\n",
    "YFs=[[YF] for i in range(5000)]\n",
    "X=np.append(X, XFs, axis=1)\n",
    "X=np.append(X, YFs, axis=1)\n",
    "Y = calcular_distancia(X[:, 0],X[:, 1],XF,YF)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "#training_data = np.append(X,Y, axis=1)\n",
    "training_data = Y\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#training_data = scaler.fit_transform(training_data)\n",
    "training_data = scaler.fit_transform(training_data.reshape(-1, 1))#Estirarlo\n",
    "\n",
    "##TIMESTEPS\n",
    "x_training_data = []\n",
    "y_training_data =[]\n",
    "for i in range(100, len(training_data)):\n",
    "    x_training_data.append(training_data[i-100:i, 0])\n",
    "    y_training_data.append(training_data[i, 0])\n",
    "\n",
    "x_training_data = np.array(x_training_data)\n",
    "y_training_data = np.array(y_training_data)\n",
    "\n",
    "print(x_training_data.shape)\n",
    "print(y_training_data.shape)\n",
    "\n",
    "x_training_data = np.reshape(x_training_data, (x_training_data.shape[0], x_training_data.shape[1], 1))\n",
    "print(x_training_data.shape)\n",
    "\n",
    "rnn = Sequential()\n",
    "rnn.add(LSTM(units = 45, return_sequences = True, input_shape = (x_training_data.shape[1], 1)))\n",
    "rnn.add(Dropout(0.2))\n",
    "for i in [True, True, False]:\n",
    "    rnn.add(LSTM(units = 45, return_sequences = i))\n",
    "    rnn.add(Dropout(0.2))\n",
    "    \n",
    "rnn.add(Dense(units = 1))\n",
    "rnn.compile(optimizer = 'adam', loss = 'mean_squared_error', verbose=0)\n",
    "rnn.fit(x_training_data, y_training_data, epochs = 100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de transformación\n",
    "Es una práctica común, en las redes neuronales, normalizar el conjunto de datos de entrenamiento, pues se ha demostrado que las redes neuronales aprenden mejor con valores pequeños entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T13:13:00.650795Z",
     "start_time": "2022-05-30T13:13:00.626791Z"
    }
   },
   "outputs": [],
   "source": [
    "def transformar(X,Y):\n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    x_scale = scaler_x.fit_transform(X)\n",
    "    y_scale = scaler_y.fit_transform(Y)\n",
    "    return (x_scale,y_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
